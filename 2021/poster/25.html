<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>MESS: Manifold Embedding Motivated Super Sampling</title>
<link rel="stylesheet" href="/2021/css/main.css">
<link rel="canonical" href="https://www.sisap.org/2021/poster/25.html">
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
<div id="page">
<header>
<img src="/2021/images/header-cherry.jpg" alt="" id="topbg" />
<a href="/2021/" id="headerlogo"><img src="/2021/images/sisap.png" alt="SISAP" /><br>
<big>SISAP 2021</big><br> Sept 29 &ndash; Oct 01<br> Dortmund, Germany</a>
</header>
<main id="main">
<h1>MESS: Manifold Embedding Motivated Super Sampling</h1>
<p><strong>Erik Thordsen and Erich Schubert</strong></p>
<h2>Motivation</h2>
<p>Local intrinsic dimensionality estimation with Euclidean distance-based k-neighborhoods tends to give unstable results when using too few neighbors or too large neighborhood radii.
Using too few neighbors is, e.g., prone to fluctuations in density and noise.
Too large neighborhood radii can lead to including sections of the manifold that are geodesically distant, thereby raising the LID, or discarding small local features, thus lowering the LID.
If possible, we would like to have more neighbors in small neighborhoods.
By using locally linear approximations of the manifold’s embedding function from the δ-dimensional parameter space to the d-dimensional feature space, we hope to create additional on-manifold points.</p>
<h2>Core Concept</h2>
<p>We estimate local covariance matrices around all original points and generate supersamples from these distributions.
In an additional step, the generated samples are pushed towards the manifold.
If we generate, e.g., 50 points per original sample, we then have 50 times as many points in the same neighborhood radius as before and can perform LID estimation on much more points for the same appropriately small neighborhood size.</p>
<table>
	<tr>
		<td width="30%" style="padding:0"><img src="thordsen/swiss_roll/2100.png" /></td>
		<td width="30%" style="padding:0"><img src="thordsen/swiss_roll/ext_42000.png" /></td>
		<td width="34.7792706334%" style="padding:0"><img src="thordsen/swiss_roll/ext_corr_42000.png" /></td>
	</tr>
	<tr>
		<td><p align="center">Original data</p></td>
		<td><p align="center">Raw supersamples</p></td>
		<td><p align="center">Corrected supersamples</p></td>
	</tr>
</table>
<h2>Complementary Information</h2>
<p>We currently know angle- and distance-based LID estimators but have not closed the gap between the two.
Geometry-based supersampling features both aspects and can enrich both approaches.
Geometric information is preserved in the sampling process and distance information are added as the geometry around distant points has less impact on local angle observations.
By overlapping local supersampling distributions and correcting with a set of neighboring original points, the supersamples within a ball aggregate information from a larger environment.
This adds additional information whilst not exceeding local geometry.</p>
<h2>Linear Embedding Approximations</h2>
<p>Assuming a locally linear manifold, and embedding function \(E: \mathbb{R}^\delta \to \mathbb{R}^d\) and its Jacobian \(\nabla E: \mathbb{R}^\delta \to \mathbb{R}^{d \times \delta}\) exist.
Then for small ε:</p>
\[Cov[E(B_\varepsilon(\tilde{x}))] \approx \frac{\varepsilon^2}{\delta + 2} \nabla E(\tilde{x})\nabla E(\tilde{x})^T\]
<p>for any \(\tilde{x}\) in the domain of E.
That is, in the ideal case, local covariances yield information on the locally linear approximation \(\nabla E(\tilde{x})\) of E at \(\tilde{x}\).
As covariance matrices are positive semidefinite and symmetric, all possible decompositions \(\Sigma = AA^T\) (e.g. Cholesky decomposition or Eigendecomposition) are equivalent up to rotation and reflection.
So any spherically symmetric distribution behaves linearly transformed with any such decomposition in the same way as with \(\nabla E(\tilde{x})\).</p>
<h2>Methods</h2>
<p>The approach is - aside from the linear embedding approximation hypothesis - mostly heuristic in nature.
That is why we evaluated multiple approaches to supersample generation and correction.
The correction step involves a weighted mean over multiple candidates, each representing a correction as per the locally linear approximation at some original point.</p>
<table>
  <thead>
    <tr>
      <th>Step</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Supersample Generation</td>
      <td>Multivariate normal distribution based on local covariances.</td>
    </tr>
    <tr>
      <td>Supersample Generation</td>
      <td>Uniform d-ball scaled with Cholesky decomposition of local covariances.</td>
    </tr>
    <tr>
      <td>Supersample Generation</td>
      <td>Uniform d-ball stretched to δ-expansion and scaled with Eigen decomposition of local covariances.</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td>Correction Candidate Generation</td>
      <td>Rotating supersample around original point by multiplying with covariance matrix and rescaling. Scales quadratic with eigenvalues of covariance matrix.</td>
    </tr>
    <tr>
      <td>Correction Candidate Generation</td>
      <td>Rotating supersample around original point by multiplying with Cholesky decomposition of covariance matrix and rescaling. Scales linearly with eigenvalues of covariance matrix.</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td>Correction Candidate Weighting</td>
      <td>Inverse Euclidean distance weighting.</td>
    </tr>
    <tr>
      <td>Correction Candidate Weighting</td>
      <td>Inverse Mahalanobis distance weighting as per local covariance of original point.</td>
    </tr>
    <tr>
      <td>Correction Candidate Weighting</td>
      <td>Inverse Mahalanobis distance weighting as per local covariance of supersampled point (estimated with original points).</td>
    </tr>
  </tbody>
</table>
<p>This gives 3·2·3=18 possible combinations of methods.
Additional methods were evaluated but did not perform well enough to be considered.</p>
<h2>Evaluation</h2>
<p>Our evaluation showed that ID estimate quality of both angle- and distance-based estimates can be improved, albeit at the cost of computational effort due to largely increased neighborhood sizes.</p>
<div align="center">
	<div>
		<img src="thordsen/moebius/base.png" height="150px" />
		<img src="thordsen/moebius/supersampled.png" height="150px" />
	</div>
	<p>
		ABID estimates of Moebius band (δ=2, d=3) without (left) and with (right) MESS.
	</p>
</div>
<div align="center">
	<div>
		<img src="thordsen/moebius/histograms_abids.png" height="150px" />
		<img src="thordsen/moebius/histograms_mle_lids.png" height="150px" />
	</div>
	<p>
		ID estimate distribution of Moebius band (δ=2, d=3) for angle-based ABID and distance-based Hill estimators without (orange) and with (blue) MESS.
	</p>
</div>
<p>The overlapping distributions blur out the local geometry well enough to lower the local LID estimate variance, strengthening the semantic correlation between estimates and geometry.</p>
<p>The most promising generation method are multivariate normal distributions, the best candidate weights are the Mahalanobis distance-based ones (all giving extremely similar results) and both candidate generation methods give acceptable results.
Covariance-based correction constraints the estimates stronger onto the manifold than Cholesky decomposition-based correction which may or may not be preferred.</p>
<p>The best neighborhood sizes for covariance estimation appears to be the one which minimizes the (normalized) ID estimate variance. This coincides with the intuition of a narrow and “precise” ID estimate distribution.</p>
<div align="center">
	<div>
		<img src="thordsen/parameters/m4_median_k1.png" height="200px" />
		<img src="thordsen/parameters/m4_std_k1.png" height="200px" />
	</div>
	<p>
		Median ID estimate and ID estimate variance for synthetic data set (δ=4, d=8) for angle-based ABID (blue) and distance-based Hill (green) estimators.
		Lowest variance is approximately at best median ID estimate.
	</p>
</div>
<h2>Beyond LID Estimation</h2>
<p>Data generated with MESS is faithful to an implicit manifold model (δ not required as parameter; no manifold learning required) and can be used in other tasks, like classification, as well.
It is a potentially better suited over-/supersampling approach for manifold-based or -related methods than linear interpolation-based approaches like, e.g., SMOTE as it better preserves the manifold structure.</p>
<div align="center">
	<div>
		<img src="thordsen/parameters/m4_hist_abid.png" height="200px" />
		<img src="thordsen/parameters/m4_hist_mle.png" height="200px" />
	</div>
	<p>
		ID estimate distribution (δ=4, d=8) for angle-based ABID and distance-based Hill estimators without over-/supersampling (blue), with SMOTE oversampling (red), and with MESS supersampling (green).
	</p>
</div>
<h2>Visual Examples</h2>
<p>Below are two examples of MESS supersampling from real data sets.
The first example shows supersamples based on MNIST instances and the second example a supersampled 3D scan with surface normals.
In both cases, MESS generates supersamples on the manifolds and is capable of “filling gaps” in the original data, which would not be possible with SMOTE-style linear-interpolation.</p>
<div align="center">
	<div>
		<img src="thordsen/mnist/25_base.png" width="15%" />
		<img src="thordsen/mnist/25_ext_corr.png" width="75%" />
	</div>
	<p>
		Original MNIST instance (left), MESS supersamples (top row) and their respective nearest neighbor from the original data.
		Generated supersamples are distinct from original instances but in-distribution.
	</p>
</div>
<table>
	<tr>
		<td width="30%" style="padding:0"><img src="thordsen/dragon/300000.png" /></td>
		<td width="30%" style="padding:0"><img src="thordsen/dragon/15000.png" /></td>
		<td width="30%" style="padding:0"><img src="thordsen/dragon/ext_corr_300000.png" /></td>
	</tr>
	<tr>
		<td><p align="center">Original data (300k points, δ=2, d=6 due to surface normals)</p></td>
		<td><p align="center">Sample of original data (15k points)</p></td>
		<td><p align="center">MESS reconstruction (including surface normals) from sample (300k points)</p></td>
	</tr>
</table>
<p><a href="https://link.springer.com/chapter/10.1007/978-3-030-89657-7_18">Paper</a></p>
<p><a href="https://arxiv.org/pdf/2107.06566">arXiv preprint</a></p>
<p><a href="https://www.youtube.com/watch?v=6xoU9EIiRdo&amp;list=PLU6sx10A4i3YMTkRclcn8HEXPYWZrLJdo">Video Presentation</a></p>
</main>
<nav id="sidebar">
<h2><a class="top" href="/2021/">SISAP 2021</a></h2>
<ul>
<li><a href="/2021/">Home</a></li>
<li><a href="/2021/callforpapers.html">Call for Research Contributions</a></li>
<li><a href="/2021/specialsessions.html">Call for Special Session Submissions</a></li>
<li><a href="/2021/doctoralsymposium.html">Call for Doctoral Symposium Papers</a></li>
<li><a href="/2021/organization.html">Organization</a></li>
<li><a href="/2021/pc.html">Program Committee</a></li>
</ul>
<h2>Contributions</h2>
<ul>
<li><a href="/2021/guidelines.html">Submission Guidelines</a></li>
<li><a href="/2021/importantdates.html">Important Dates</a></li>
<li><a href="/2021/papers.html">Accepted Papers</a></li>
<li><a href="/2021/camerareadyversion.html">Camera Ready Version</a></li>
</ul>
<h2>Attendance</h2>
<ul>
<li><a href="/2021/registration.html">Registration</a></li>
<li><a href="/2021/conferenceoutline.html">Conference Outline</a></li>
<li><a href="/2021/conferenceprogram.html">Conference Program</a></li>
</ul>
<h2>Previous Conferences</h2>
<ul>
<li><a href="http://www.sisap.org/2020">SISAP 2020</a></li>
<li><a href="http://www.sisap.org/2019">SISAP 2019</a></li>
<li><a href="http://www.sisap.org/2018">SISAP 2018</a></li>
<li><a href="http://www.sisap.org/2017">SISAP 2017</a></li>
<li><a href="http://www.sisap.org/2016">SISAP 2016</a></li>
<li><a href="http://www.sisap.org/">Earlier SISAPs</a></li>
</ul>
</nav>
<aside>
<h2 style="color:#900">Virtual or Hybrid?</h2>
<p><b>Virtual</b></p>
<p>The conference will be entirely <em>virtual</em>.
Current development in Europe is too dynamic.</p>
<h2>News</h2>
<p><a href="https://link.springer.com/book/10.1007/978-3-030-89657-7">Proceedings</a></p>
<p><a href="https://www.youtube.com/playlist?list=PLU6sx10A4i3YMTkRclcn8HEXPYWZrLJdo">SISAP video presentations</a></p>
<hr>
<p><a href="/2021/awards.html">Best paper awards</a></p>
<hr>
<p><a href="/2021/conferenceprogram.html">Conference program</a></p>
<hr>
<p><a href="/2021/registration.html">Free registration</a></p>
<hr>
<!--<p>Please <b>upload your video recordings</b>!</p>
<hr>
<p><a href="/2021/camerareadyversion.html">Camera-ready instructions</a>
were mailed to corresponding authors.</p>
<hr> -->
<a href="/2021/papers.html">Accepted Papers</a>
<hr>
<!--<p>Notifications: July&nbsp;24,&nbsp;2021</p>
<hr>-->
<p>May 31 2021: SISAP is now a <a href="http://portal.core.edu.au/conf-ranks/2240/">CORE&nbsp;Rank&nbsp;B</a> conference.</p>
<hr>
<p>The <a href="/2021/specialsessions.html">call for special sessions submissions</a> is posted</p>
<hr>
<p>The <a href="/2021/callforpapers.html">call for papers</a> is posted on the web site</p>
<h3>Submission deadline:</h3>
<p><a href="/2021/importantdates.html">June 14, 2021 AoE (<b>closed</b>)</a></p>
</aside>
<footer>
<a href="http://www.springer.com/computer/lncs"><img src="/2021/images/LNCS.jpg"/></a>
<a href="http://www.journals.elsevier.com/information-systems/"><img src="/2021/images/is.png" /></a>
<!--
<a href="https://www.google.com/"><img src="images/google.png"/></a>
-->
<hr>
<div id="credits">
Image credit:
Mathetower with cherry blossoms is derived work based on a
<a href="https://commons.wikimedia.org/wiki/File:Mathetower_TU_Dortmund.jpg">CC-BY-SA 3.0 image by Sonja Ludwig</a>
<br>
Legal contact for 2021 only: <a href="https://www-ai.cs.uni-dortmund.de/PERSONAL/schubert.html">Erich Schubert</a>.
</div>
</footer>
</div>
<script src="/2021/js/poster.js"></script>
</body>
</html>
