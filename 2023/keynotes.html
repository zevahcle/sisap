<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv='cache-control' content='no-cache'> 
<meta http-equiv='expires' content='0'> 
<meta http-equiv='pragma' content='no-cache'>
  <title>Doctoral Symposium – 16th International Conference on Similarity Search and Applications, SISAP 2023</title>
  <link rel="stylesheet" href="/2023/css/main.css">
  <link rel="canonical" href="https://www.sisap.org/2023/cfp.html">
</head>

<body>
  <div id="page">
    <header>
      <img style="width:100%" src="/2023/images/coruna.png" alt="A Coruña, Spain" id="topbg" />
      <a href="/" id="headerlogo"><img src="/2023/images/sisap.png" alt="SISAP" /><br>
        <big>SISAP 2023</big><br> Oct 9-11, A Coruña, Spain</a>
    </header>
    <main id="main">

      <h1>Keynote Speakers</h1>
      <h2>Michael Houle</h2>
      <h3>New Jersey Institute of Technology</h3>
      <p><b>Title: From Intrinsic Dimensionality to Chaos and Control: Towards a Unified Theoretical View</b></p>
      <p><b>Abstract:</b></p>
      <p>Researchers have long considered the analysis of similarity applications in terms of the intrinsic
        dimensionality (ID) of the data. Although traditionally ID has been viewed as a characterization of the
        complexity of discrete datasets, more recently a local model of intrinsic dimensionality (LID) has been extended
        to the case of smooth growth functions in general, and distance distributions in particular, from its first
        principles in terms of similarity, features, and probability. Since then, LID has found applications — practical
        as well as theoretical — in such areas as similarity search, data mining, and deep learning. LID has also been
        shown to be equivalent under transformation to the well-established statistical framework of extreme value
        theory (EVT). In this presentation, we will survey some of the wider connections between ID and other forms of
        complexity analysis, including EVT, power-law distributions, chaos theory, and control theory, and show how LID
        can serve as a unifying framework for the understanding of these theories. Finally, we will reinterpret recent
        empirical findings in the area of deep learning in light of these connections.</p>
      <p><b>Bio:</b></p>
      <p>Michael Houle obtained his PhD degree in 1989 from McGill University in Canada, in the area of computational
        geometry. Since then, he developed research interests in algorithmics, data structures, and relational
        visualization, first at Kyushu University and the University of Tokyo in Japan, and from 1992 at the University
        of Newcastle and the University of Sydney in Australia. From 2001 to 2004, while at IBM Japan's Tokyo Research
        Laboratory, he first began working on approximate similarity search and shared-neighbor clustering methods for
        data mining applications. From 2004, at the National Institute of Informatics, Tokyo, his research interests
        expanded to include dimensionality and scalability in the context of fundamental AI / machine learning / data
        mining tasks such as search, clustering, classification, and outlier detection. In 2021, he relocated to
        Vancouver, BC, Canada. Currently he is with the New Jersey Institute of Technology in Newark, NJ, USA, and
        divides his time between Newark and Vancouver.</p>

      <h2>Yury Malkov</h2>
      <h3>VerSe Innovation</h3>
      <p><b>Title:</b>The Rise of HNSW: Understanding Key Factors Driving the Adoption of Search Libraries in Machine
        Learning</p>
      <p><b>Abstract:</b></p>
      <p>As representation learning and large language models continue to evolve, the need for efficient similarity
        search techniques has grown exponentially in the last few years. HNSW has emerged as a leading algorithm for
        nearest neighbor search, finding applications in a diverse range of products such as Weavite, Qdrant, Vespa,
        Milvus, Zilliz, Faiss, Elasticsearch, Redis and others. In this talk, we will explore the core principles and
        development of HNSW, as well as the key design decisions and factors that have contributed to its widespread
        adoption beyond its high performance. Through these insights, we aim to guide developers in creating innovative
        libraries and solutions to address the ever-increasing demand for efficient search libraries and machine
        learning tools in general.</p>

      <h2>Julio Gonzalo</h2>
      <h3>Universidad Nacional de Educación a Distancia (UNED), Spain</h3>
      <p><b>Title:</b>Towards a Universal Similarity Function: the Information Contrast Model and its Application as
        Evaluation Metric in Artificial Intelligence Tasks</p>
      <p><b>Abstract:</b></p>
      <p>Computing similarity implies, at least, two aspects: how to represent items, and how to compare item
        representations (similarity functions). Item representation is a task-dependent problem, but what about
        similarity functions? Is it possible
        to study the design of optimal similarity functions from a universal, application-free perspective?

        In the talk, we start by proposing a set of formal constraints on the space of permissible similarity functions
        for Information Access problems and comparing it with other related axiomatic formulations of similarity in
        other fields (cognitive science and algebra). Then, we propose a new parameterized similarity function, ICM,
        which satisfies all constraints for a given range of values of its parameters. We discuss the usefulness of ICM
        in two very different application domains: first, to compute textual similarity under different application
        scenarios and representation paradigms, which was the original task for which ICM was designed. But ICM can be
        successfully applied outside its intended original scope: in the talk, we show how it can be used as an
        evaluation measure in Artificial Intelligence that computes the similarity between system outputs and gold
        standards, and how it may bring formal and empirical advantages in this area.</p>

      <p><b>Bio:</b></p>
      <p>
        Julio Gonzalo is director of the UNED Research Center in Natural Language Processing (NLP) and
        Information Retrieval (IR) and deputy Vicerrector of Research at UNED. Along his career he has worked on topics
        such as online reputation monitoring, Information Access technologies for Social Media, interactive
        cross-language search, toxicity and misinformation in Social Media, computational creativity and semantic
        similarity. He has also worked extensively in the design and assessment of evaluation metrics for a wide range
        of Artificial Intelligence problems, which led to a Google Faculty Research Award (together with Enrique Amigó
        and Stefano Mizzaro) for his work in this area. He has recently been co-chair of ACM SIGIR 2022 and co-chair of
        IberLEF, the annual evaluation campaign for NLP systems in Spanish and other Iberian languages (2019-2022).
      </p>


    </main>
    <nav id="sidebar">
      <h2><a class="top" href="/2023/">SISAP 2023</a></h2>
      <ul>
        <li><a href="/2023/index.html">Home</a></li>
        <li><a href="/2023/callforpapers.html">Call for Research Contributions</a></li>
        <li><a href="/2023/doctoralsymposium.html">Call for Doctoral Symposium Papers</a></li>
        <li><a href="https://sisap-challenges.github.io/">Call for SISAP Indexing Challenge</a></li>
        <li><a href="/2023/keynotes.html">Keynote Speakers</a></li>
        <li><a href="/2023/organization.html">Organization</a></li>
        <li><a href="/2023/pc.html">Program Committee</a></li>
        <li><a href="/2023/channels.html">Information channels</a></li>
      </ul>
      <h2>Contributions</h2>
        <ul>
            <li><a href="/2023/guidelines.html">Submission Guidelines</a></li>
            <li><a href="/2023/importantdates.html">Important Dates</a></li>
            <li><a href="/2023/accepted.html">Accepted Papers</a></li>
            <li><a href="/2023/cameraready.html">Camera Ready Version</a></li>
            <li>Proceedings</li>
            <li>Awards</li>
        </ul>
        </ul>
        <h2>Attendance</h2>
        <ul>
            <li><a href="/2023/venue.html">Conference Venue</a></li>
            <li><a href="/2023/registration.html">Registration</a></li>
            <li><a href="/2023/accommodation.html">Accommodation</a></li>
            <li><a href="/2023/program.html">Conference Program</a></li>

        </ul>
      <h2>Previous Conferences</h2>
      <ul>
        <li><a href="http://www.sisap.org/2022/">SISAP 2022</a></li>
        <li><a href="http://www.sisap.org/2021/">SISAP 2021</a></li>
        <li><a href="http://www.sisap.org/2020/">SISAP 2020</a></li>
        <li><a href="http://www.sisap.org/2019/">SISAP 2019</a></li>
        <li><a href="http://www.sisap.org/2018/">SISAP 2018</a></li>
        <li><a href="http://www.sisap.org/2017/">SISAP 2017</a></li>
        <li><a href="http://www.sisap.org/">Earlier SISAPs</a></li>
      </ul>
    </nav>
    <aside>
      <h2>News</h2>
      <p>SISAP is a <a href="http://portal.core.edu.au/conf-ranks/2240/">CORE&nbsp;Rank&nbsp;B</a> conference.</p>
      <hr>
    </aside>
    <footer>
      <a href="http://www.udc.gal"><img src="/2023/images/udc.png" /></a><br><br>
      <a href="http://www.springer.com/gp/computer-science/lncs"><img src="/2023/images/LNCS.jpg" /></a>
      <a href="http://www.journals.elsevier.com/information-systems/"><img src="/2023/images/is.png" /></a>

    </footer>
  </div>
</body>

</html>