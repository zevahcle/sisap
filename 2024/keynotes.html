<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv='cache-control' content='no-cache'>
  <meta http-equiv='expires' content='0'>
  <meta http-equiv='pragma' content='no-cache'>
  <title>SISAP 2024</title>
  <link rel="stylesheet" href="/2024/css/main.css">
  <link rel="canonical" href="https://www.sisap.org/2024/">
</head>

<body>
  <div id="page">
    <header>
      <img style="width:100%" src="/2024/images/brown.png" alt="Brown University" id="topbg" />
      <a href="/" id="headerlogo"><img src="/2024/images/sisap.png" alt="SISAP" /><br>
        <big>SISAP 2024</big><br> November 4th-6th <br>Providence, RI, USA</a>
    </header>
    <main id="main">

      <h1>Keynote Speakers</h1>

      <h2>Piotr Indyk</h2>
      <h3>Professor of Electrical Engineering and Computer Science at MIT</h3>

      <p><b>Title:</b> Graph-based algorithms for similarity search: challenges and opportunities</p>

      <p><b>Abstract:</b></p>
      <p>
        Over the last few years, graph-based approaches to nearest neighbor search have gained renewed interest. 
        Algorithms such as HNSW, NSG, and DiskANN have become popular tools in practice. These algorithms are highly 
        versatile and come equipped with efficient implementations. At the same time, the theoretical guarantees of 
        these algorithms are relatively limited. For instance, it has been observed (Indyk, Xu '23) that there exist 
        simple low-dimensional datasets for which most of these algorithms exhibit query times that scale linearly with 
        the dataset size. In this talk, I will discuss some of the challenges and opportunities presented by this class 
        of algorithms.
      </p>

      <p><b>Bio:</b></p>
      <p>
        Piotr Indyk is the Thomas D. and Virginia W. Cabot Professor of Electrical Engineering and Computer Science at 
        the Massachusetts Institute of Technology, where he has been on the faculty since 2000. He graduated from the 
        University of Warsaw in 1995 and received his Ph.D. in Computer Science from Stanford University in 2001. He 
        received the Packard Fellowship in 2003 and the Simons Investigator Award in 2013. He is also a co-winner of the
         2012 Paris Kanellakis Theory and Practice Award for his work on Locality-Sensitive Hashing. Piotr Indyk is a 
         fellow of the Association for Computing Machinery and a member of the American Academy of Arts and Sciences and
          the National Academy of Sciences.
      </p>
        


      <h2>Bradley C. Love</h2>
      <h3>Professor of Cognitive and Decision Sciences at University College London </h3>

      <p><b>Title:</b> Embeddings of and for the mind</p>

      <p><b>Abstract:</b></p>
      <p>
        A variety of domains, including images, text, consumer choice, and brain activity, can be captured in embedding 
        spaces. In this talk, I will consider how to collect very large semantic embeddings from human similarity 
        judgments. We can use these embeddings to evaluate how well deep learning models align with humans. One 
        conclusion is that models that tend to be better from an engineering standpoint are worse as models of humans. 
        Should unconstrained embeddings or embeddings constrained to be non-negative should be preferred? I'll suggest 
        there is a tradeoff in which non-negative embeddings, which tend to be more interpretable, are worse for encoding 
        information but better for decoding. In the second part of the talk, I will consider whether agents can learn in 
        an unsupervised manner by aligning embeddings across modalities (<i>e.g.</i>, images and words) by respecting parallel 
        similarity relations across domains. I'll present evidence that adults spontaneously align modalities during 
        learning and that children rapidly learn new words through this alignment process.
      </p>

      <p><b>Bio:</b></p>
      <p>
        Bradley C. Love is a Professor of Cognitive and Decision Sciences in Experimental Psychology at University 
        College London (UCL). He is also a distinguished fellow at The Alan Turing Institute for data science and AI, as
         well as the European Lab for Learning \& Intelligent Systems (ELLIS). His research lab is dedicated to 
         advancing the understanding of human learning and decision-making by integrating behavioral, computational, and
          neuroscience perspectives. Currently, his team is pioneering efforts in large-scale modeling of brain and 
          behavior using deep learning techniques. Additionally, they are developing BrainGPT, an innovative tool 
          designed to assist neuroscience researchers by leveraging large language models.
      </p>

      <h2>Sanjiv Kumar</h2>
      <h3>Google Fellow and VP at Google Research</h3>
      <p><b>Title:</b> Towards massive scale similarity search</p>

      <p><b>Abstract:</b></p>
      <p>
      Beyond the traditional search and recommendation tasks in massive datasets, the recent revolution in deep learning
      and Large Language models (LLMs) is driving huge interest in efficient search in large databases. Fast search is 
      proving to be essential for new applications like Retrieval-Augmented Generative AI (RAG) in addition to enabling 
      efficient variants of LLMs. Most of these applications need fast techniques for Maximum Inner Product Search 
      (MIPS). In this talk, I will describe the design of new techniques that effectively combine data partitioning with
      compression to achieve the state-of-the-art MIPS search. We have open-sourced the resulting system (ScaNN) which 
      is used extensively by the external community. I will conclude with open questions in the area of similarity 
      search and a discussion on other emerging alternatives such as generative retrieval based on LLMs. 
      </p>

      <p><b>Bio:</b></p>
      <p>
        Sanjiv Kumar is a Google Fellow and VP at Google Research, where he is leading a team on theory and applications
         of large ML Foundational Models and Generative AI. His recent research interests include rethinking existing 
         modeling and compute paradigms in LLMs with a focus on developing alternative techniques that allow fast 
         training and inference. He also leads development of massive scale similarity search techniques, which are 
         widely adopted in Google and the open-source community. He has published more than 125 papers and holds 
         60+ patents in the area of ML and Computer Vision. His work on convergence of Adam received the best paper
         award in ICLR, 2018. He is an action editor of JMLR and holds a PhD from the School of Computer Science
         at Carnegie Mellon University. More information can be found at: <a href="http://www.sanjivk.com.">http://www.sanjivk.com</a>.
      </p>

    </main>
    <nav id="sidebar">
      <h2><a class="top" href="/2024/">SISAP 2024</a></h2>
      <ul>
          <li><a href="/2024/index.html">Home</a></li>
          <li><a href="/2024/callforpapers.html">Call for Research Contributions</a></li>
          <!-- <li><a href="/2024/index.html">Call for Doctoral Symposium Papers</a></li> -->
          <li><a href="https://sisap-challenges.github.io/">Call for SISAP Indexing Challenge</a></li>
          <li><a href="/2024/keynotes.html">Keynote Speakers</a></li>
          <li><a href="/2024/organization.html">Organization</a></li>
          <li><a href="/2024/pc.html">Program Committee</a></li>
          <li><a href="/2024/channels.html">Information channels</a></li>
      </ul>
      <h2>Contributions</h2>
      <ul>
          <li><a href="/2024/guidelines.html">Submission Guidelines</a></li>
          <li><a href="/2024/importantdates.html">Important Dates</a></li>
          <li><a href="/2024/accepted.html">Accepted Papers</a></li>
          <li><a href="/2024/cameraready.html">Camera Ready Version</a></li>
          <li><a href="/2024/proceedings.html">Proceedings</a></li>
          <li><a href="/2024/awards.html">Awards</a></li></ul>
      </ul>
      <h2>Attendance</h2>
      <ul>
        <li><a href="/2024/registration.html">Registration</a></li>
        <li><a href="/2024/venue.html">Conference Venue</a></li>
        <li><a href="/2024/wine.html">Wine Tasting</a></li>
        <li><a href="/2024/accommodation.html">Accommodation</a></li>
        <li><a href="/2024/program.html">Conference Program</a></li>
        <li><a href="/2024/poster.html">Poster Session</a></li>

      </ul>
      <h2>Previous Conferences</h2>
      <ul>
          <li><a href="http://www.sisap.org/2023/">SISAP 2023</a></li>
          <li><a href="http://www.sisap.org/2022/">SISAP 2022</a></li>
          <li><a href="http://www.sisap.org/2021/">SISAP 2021</a></li>
          <li><a href="http://www.sisap.org/2020/">SISAP 2020</a></li>
          <li><a href="http://www.sisap.org/2019/">SISAP 2019</a></li>
          <li><a href="http://www.sisap.org/2018/">SISAP 2018</a></li>
          <li><a href="http://www.sisap.org/2017/">SISAP 2017</a></li>
          <li><a href="http://www.sisap.org/">Earlier SISAPs</a></li>
      </ul>
  </nav>
  <aside>
    <h2>News</h2>
    Registration is <a href="/2024/registration.html">open</a>! Authors, be sure to register by the deadline.
    <hr>
    <p>SISAP is a <a href="http://portal.core.edu.au/conf-ranks/2240/">CORE&nbsp;Rank&nbsp;B</a> conference.</p>
    <hr>
    <!-- <p>The <a href="callforpapers.html">call for papers</a> is posted on the web site</p> -->
    <!--<h3>Submission deadline:</h3>
<p><a href="/2021/importantdates.html">June 14, 2021 AoE (<b>closed</b>)</a></p>-->
</aside>
<footer>
  <a href="https://www.brown.edu/"><img src="/2024/images/brown-logo.png" width="40%" height="auto"/></a><br><br>
  <a href="http://www.springer.com/gp/computer-science/lncs"><img src="/2024/images/LNCS.jpg" /></a>
  <a href="http://www.journals.elsevier.com/information-systems/"><img src="/2024/images/is.png" /></a>
  <a href="https://www.newportvineyards.com/winery/"><img src="/2024/images/logo-newport-vineyards-horizontal-full-color-edit@2x.webp" /></a>
  <a href="https://nicklecreekvineyard.com/"><img src="/2024/images/Nickle-Creek-Color-Logo.png" /></a>
  <p>
  <a href="https://www.greenvale.com/"><img src="/2024/images/logo-greenvale.png" width="30%" height="auto"/></a>
  <a href="https://store69693460.company.site/"><img src="/2024/images/logo-vinicola-total.webp" width="30%" height="auto"/></a>
  </p>
  <a href="https://shepherds.run/"><img src="/2024/images/SR_Logo.webp" /></a>
</footer>
  </div>
</body>

</html>
